"""
Football Youth Cups Scraper for Render.com
××¢×“×›×Ÿ ××ª ×”×©×¨×ª ×©×œ×š ××•×˜×•××˜×™×ª
"""

import os
import json
import time
import random
import requests
from datetime import datetime, timedelta
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options

# ×”×’×“×¨×•×ª ××”××©×ª× ×™ ×¡×‘×™×‘×”
API_URL = os.getenv('API_URL', 'https://yty.s904.upress.link/api/update.php')
API_KEY = os.getenv('API_KEY', 'change-this-to-secret-key')

# ×¨×©×™××ª ×”×œ×™×’×•×ª
YOUTH_CUPS = [
    {'id': 617, 'name': '×’×‘×™×¢ ×”××“×™× ×” × ×©×™×', 'category': '× ×©×™×'},
    {'id': 586, 'name': '×’×‘×™×¢ ×œ× ×•×¢×¨ ×¢"×© ××‘×™ ×¨×Ÿ ×–"×œ', 'category': '× ×•×¢×¨'},
    {'id': 692, 'name': '×’×‘×™×¢ × ×¢×¨×•×ª ×¢"×© ×¦×‘×™ (×•×™×œ×™) ×•×™×œ×™× ×’×¨ ×–"×œ', 'category': '× ×¢×¨×•×ª'},
    {'id': 587, 'name': '×’×‘×™×¢ × ×¢×¨×™× ×\' ×¢"×© ×—×™×™× ×”×‘×¨×¤×œ×“ ×–"×œ', 'category': '× ×¢×¨×™× ×\''},
    {'id': 813, 'name': '×’×‘×™×¢ ×”××“×™× ×” ×œ× ×¢×¨×•×ª ×\' ×¢\'\'×© ×××™ × ×¢×™× ×–\'\'×œ', 'category': '× ×¢×¨×•×ª ×\''},
    {'id': 588, 'name': '×’×‘×™×¢ × ×¢×¨×™× ×‘\' ×¢"×© ×‘×¨×•×š ×× ×“×œ×‘×œ×™×˜ ×–"×œ', 'category': '× ×¢×¨×™× ×‘\''},
    {'id': 589, 'name': '×’×‘×™×¢ × ×¢×¨×™× ×’ ×¢"×© ×–.×§×œ×™××•×˜ ×–"×œ', 'category': '× ×¢×¨×™× ×’\''},
    {'id': 590, 'name': '×’×‘×™×¢ ×™×œ×“×™× ×\' ×¢"×© ×“×•×“ ×©×•×•×™×¦×¨ ×–"×œ', 'category': '×™×œ×“×™× ×\''},
    {'id': 718, 'name': '×’×‘×™×¢ ×”××“×™× ×” ×œ×™×œ×“×•×ª ×\' ×¢"×© ×™×”×œ ×©×¨×¢×‘×™ ×–"×œ', 'category': '×™×œ×“×•×ª ×\''},
    {'id': 591, 'name': '×’×‘×™×¢ ×™×œ×“×™× ×‘\' ×¢"×© ×©××•××œ ×¡×•×—×¨ ×–"×œ', 'category': '×™×œ×“×™× ×‘\''},
    {'id': 919, 'name': '×’×‘×™×¢ ×”××“×™× ×” ×œ×™×œ×“×•×ª ×‘\'', 'category': '×™×œ×“×•×ª ×‘\''},
    {'id': 592, 'name': '×’×‘×™×¢ ×™×œ×“×™× ×’\' ×¢"×© ×™×¢×§×‘ ×’×¨×•× ×“××Ÿ ×–"×œ', 'category': '×™×œ×“×™× ×’\''},
    {'id': 593, 'name': '×’×‘×™×¢ ×™×œ×“×™× ×˜×¨×•× ×\'', 'category': '×˜×¨×•× ×\''}
]

SEASON_ID = 27

class YouthCupsScraper:
    def __init__(self):
        options = Options()
        options.add_argument('--headless')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-blink-features=AutomationControlled')
        
        # User-Agent ××§×¨××™
        user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0',
        ]
        options.add_argument(f'user-agent={random.choice(user_agents)}')
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        
        self.driver = webdriver.Chrome(options=options)
        self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        self.all_matches = []
    
    def extract_matches_from_cup(self, cup_id, cup_name, category):
        url = f"https://www.football.org.il/national-cup/?national_cup_id={cup_id}&season_id={SEASON_ID}"
        print(f"ğŸ”„ {cup_name}...")
        
        try:
            self.driver.get(url)
            time.sleep(random.uniform(3, 6))
            
            match_rows = self.driver.find_elements(By.CSS_SELECTOR, '.results-grid .table_row')
            matches = []
            
            for index, row in enumerate(match_rows):
                try:
                    date = row.find_element(By.CSS_SELECTOR, '.game-date').text.strip() if row.find_elements(By.CSS_SELECTOR, '.game-date') else ''
                    
                    teams = row.find_elements(By.CSS_SELECTOR, '.team-name-text')
                    home_team = teams[0].text.replace('-', '').strip() if len(teams) > 0 else ''
                    away_team = teams[1].text.strip() if len(teams) > 1 else ''
                    
                    field_elements = row.find_elements(By.CSS_SELECTOR, '.table_col.align_content')
                    field = field_elements[2].text.replace('××’×¨×©', '').strip() if len(field_elements) > 2 else ''
                    
                    # ×©×¢×”
                    match_time = ''
                    time_elements = row.find_elements(By.CSS_SELECTOR, '.table_col')
                    for elem in time_elements:
                        text = elem.text.strip()
                        if ':' in text and len(text) == 5 and text.count(':') == 1:
                            match_time = text
                            break
                    
                    result = row.find_element(By.CSS_SELECTOR, '.result').text.replace('×ª×•×¦××”', '').strip() if row.find_elements(By.CSS_SELECTOR, '.result') else ''
                    
                    extra_elements = row.find_elements(By.CSS_SELECTOR, '.new-desktop-only')
                    extra_time = extra_elements[0].text.replace('×”××¨×›×”', '').strip() if len(extra_elements) > 0 else ''
                    penalties = extra_elements[1].text.replace('×‘.×”×›×¨×¢×”', '').strip() if len(extra_elements) > 1 else ''
                    
                    link = row.get_attribute('href') or ''
                    if link:
                        link = f"https://www.football.org.il{link}"
                    
                    home_score, away_score = None, None
                    if result and '-' in result:
                        parts = result.split('-')
                        try:
                            home_score = int(parts[0].strip())
                            away_score = int(parts[1].strip())
                        except:
                            pass
                    
                    matches.append({
                        'cupId': cup_id,
                        'cupName': cup_name,
                        'category': category,
                        'index': index + 1,
                        'date': date,
                        'time': match_time or None,
                        'homeTeam': home_team,
                        'awayTeam': away_team,
                        'field': field,
                        'score': {'home': home_score, 'away': away_score},
                        'extraTime': extra_time or None,
                        'penalties': penalties or None,
                        'link': link,
                        'status': 'finished' if result else 'upcoming'
                    })
                except Exception as e:
                    print(f"  âš ï¸ ×©×’×™××” ×‘×©×•×¨×” {index}: {e}")
                    continue
            
            print(f"  âœ… {len(matches)} ××©×—×§×™×")
            return matches
        except Exception as e:
            print(f"  âŒ ×©×’×™××”: {e}")
            return []
    
    def scrape_all_cups(self):
        print("="*60)
        print("ğŸš€ ××ª×—×™×œ ×©×œ×™×¤×” ××›×œ ×”×œ×™×’×•×ª")
        print("="*60)
        
        for cup in YOUTH_CUPS:
            matches = self.extract_matches_from_cup(cup['id'], cup['name'], cup['category'])
            self.all_matches.extend(matches)
            
            if cup != YOUTH_CUPS[-1]:
                delay = random.uniform(3, 8)
                time.sleep(delay)
        
        print(f"\nâœ… ×¡×”\"×›: {len(self.all_matches)} ××©×—×§×™×")
        return self.all_matches
    
    def close(self):
        self.driver.quit()


def upload_to_server(matches):
    """×©×œ×— × ×ª×•× ×™× ×œ×©×¨×ª"""
    print(f"\nğŸ“¤ ×©×•×œ×— × ×ª×•× ×™× ×œ×©×¨×ª...")
    
    try:
        response = requests.post(
            API_URL,
            json=matches,
            headers={
                'X-API-Key': API_KEY,
                'Content-Type': 'application/json'
            },
            timeout=30
        )
        
        if response.status_code == 200:
            print(f"âœ… ×”×©×¨×ª ×¢×•×“×›×Ÿ ×‘×”×¦×œ×—×”!")
            return True
        else:
            print(f"âŒ ×©×’×™××”: {response.status_code} - {response.text}")
            return False
    except Exception as e:
        print(f"âŒ ×©×’×™××” ×‘×©×œ×™×—×”: {e}")
        return False


def should_update(matches):
    """×‘×“×•×§ ×× ×¦×¨×™×š ×œ×¢×“×›×Ÿ (×”×× ×™×© ××©×—×§×™× ×¤×¢×™×œ×™×)"""
    now = datetime.now()
    
    for match in matches:
        if match['status'] == 'finished':
            continue
        
        try:
            # ×”××¨ ×ª××¨×™×š
            date_parts = match['date'].split('/')
            day, month, year = int(date_parts[0]), int(date_parts[1]), int(date_parts[2])
            
            # ×©×¢×”
            if match.get('time'):
                hour, minute = match['time'].split(':')
                hour, minute = int(hour), int(minute)
            else:
                hour, minute = 19, 0
            
            match_dt = datetime(year, month, day, hour, minute)
            
            # ×‘×“×•×§ ×—×œ×•×Ÿ ×–××Ÿ: 30 ×“×§×•×ª ×œ×¤× ×™ ×¢×“ ×©×¢×” ××—×¨×™
            start = match_dt - timedelta(minutes=30)
            end = match_dt + timedelta(hours=1)
            
            if start <= now <= end:
                return True
        except:
            continue
    
    return False


def main():
    """×¤×•× ×§×¦×™×” ×¨××©×™×ª"""
    print(f"\nğŸ• {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸŒ API URL: {API_URL}")
    
    scraper = YouthCupsScraper()
    
    try:
        # ×©×œ×•×£ × ×ª×•× ×™×
        matches = scraper.scrape_all_cups()
        
        if not matches:
            print("âŒ ×œ× × ××¦××• ××©×—×§×™×")
            return
        
        # ×‘×“×•×§ ×× ×¦×¨×™×š ×œ×¢×“×›×Ÿ
        if should_update(matches):
            print(f"\nâš¡ ×™×© ××©×—×§×™× ×¤×¢×™×œ×™× - ××¢×“×›×Ÿ!")
            upload_to_server(matches)
        else:
            print(f"\nğŸ’¤ ××™×Ÿ ××©×—×§×™× ×¤×¢×™×œ×™× - ×œ× ××¢×“×›×Ÿ")
            print(f"   (×¢×“×›×•×Ÿ ×™×§×¨×” ×¨×§ 30 ×“×§×•×ª ×œ×¤× ×™ ×¢×“ ×©×¢×” ××—×¨×™ ××©×—×§×™×)")
    
    except Exception as e:
        print(f"\nâŒ ×©×’×™××” ×›×œ×œ×™×ª: {e}")
    
    finally:
        scraper.close()
        print(f"\nâœ… ×¡×™×•×")


if __name__ == "__main__":
    main()
